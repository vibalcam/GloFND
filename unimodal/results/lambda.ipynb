{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "# load package\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator,FormatStrFormatter,MaxNLocator\n",
    "from tqdm.auto import tqdm\n",
    "import argparse\n",
    "import builtins\n",
    "from datetime import datetime\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import wandb\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from utils import utils\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import models\n",
    "# import torchvision.models as torchvision_models\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sogclr.builder\n",
    "import sogclr.loader\n",
    "import sogclr.optimizer\n",
    "import sogclr.folder # imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"glofnd/{model_idx}/checkpoint_0199.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "data = \"imagenet\"\n",
    "arch = \"resnet50\"\n",
    "batch_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "image_size = 224\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "# simclr\n",
    "augmentation1 = [\n",
    "    transforms.RandomResizedCrop(image_size, scale=(0.08, 1.)),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(0.4, 0.4, 0.2, 0.1)  # not strengthened\n",
    "    ], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomApply([sogclr.loader.GaussianBlur([.1, 2.])], p=1.0),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "]\n",
    "\n",
    "traindir = os.path.join(data, 'train')\n",
    "train_dataset = sogclr.folder.ImageFolder(\n",
    "    traindir,\n",
    "    sogclr.loader.TwoCropsTransform(transforms.Compose(augmentation1), \n",
    "                                    transforms.Compose(augmentation1)))\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=6, pin_memory=True, sampler=train_sampler, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.__dict__[arch](pretrained=False)\n",
    "\n",
    "def _build_mlp(num_layers, input_dim, mlp_dim, output_dim, last_bn=True):\n",
    "    mlp = []\n",
    "    for l in range(num_layers):\n",
    "        dim1 = input_dim if l == 0 else mlp_dim\n",
    "        dim2 = output_dim if l == num_layers - 1 else mlp_dim\n",
    "\n",
    "        mlp.append(nn.Linear(dim1, dim2, bias=False))\n",
    "\n",
    "        if l < num_layers - 1:\n",
    "            mlp.append(nn.BatchNorm1d(dim2))\n",
    "            mlp.append(nn.ReLU(inplace=True))\n",
    "        elif last_bn:\n",
    "            # follow SimCLR's design: https://github.com/google-research/simclr/blob/master/model_util.py#L157\n",
    "            # for simplicity, we further removed gamma in BN\n",
    "            mlp.append(nn.BatchNorm1d(dim2, affine=False))\n",
    "\n",
    "    return nn.Sequential(*mlp)\n",
    "\n",
    "# Remove the final fully connected layer and add an identity layer\n",
    "if hasattr(model, 'fc'):\n",
    "    linear_keyword = 'fc'\n",
    "    hidden_dim = model.fc.weight.shape[1]\n",
    "    # model.fc = nn.Identity()\n",
    "    model.fc = _build_mlp(2, hidden_dim, 2048, 128)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model architecture: {arch}\")\n",
    "\n",
    "# Load checkpoint\n",
    "if os.path.isfile(model_path):\n",
    "    print(f\"=> Loading checkpoint '{model_path}'\")\n",
    "    checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "    lda = state_dict['module.lambda_threshold.lda']\n",
    "    # get base_encoder state_dict\n",
    "    state_dict = {k.replace('module.base_encoder.', ''): v for k, v in state_dict.items() if 'module.base_encoder.' in k}\n",
    "    msg = model.load_state_dict(state_dict, strict=True)\n",
    "    print(f\"=> Loaded checkpoint with missing keys: {msg.missing_keys}\")\n",
    "    # assert all([linear_keyword in k for k in msg.missing_keys]), \"Missing keys should be linear layers\"\n",
    "    model.eval()\n",
    "else:\n",
    "    print(f\"Warning: Checkpoint {model_path} not found!\")\n",
    "    raise FileNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6), dpi=300)\n",
    "# mpl.rcParams['pdf.fonttype'] = 42\n",
    "# mpl.rcParams['ps.fonttype'] = 42\n",
    "# mpl.rcParams['font.family'] = 'Arial'\n",
    "            \n",
    "# Plot the kernel density plot for lda\n",
    "v_plot = lda.squeeze().numpy()\n",
    "ax = sns.kdeplot(v_plot, color='blue', legend=False, linewidth=12)\n",
    "ax.yaxis.set_visible(False)\n",
    "plt.tick_params(axis='x', labelsize=40)\n",
    "plt.xlabel(\"\\u03BB\", fontsize=45)\n",
    "plt.xlim(0.1, 0.6)\n",
    "# plt.xticks(np.arange(0.1, 0.7, 0.1))\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"plots/lda_199.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "hidden_list1 = []\n",
    "hidden_list2 = []\n",
    "indices = []\n",
    "labels_list = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    model.cuda()\n",
    "\n",
    "    for images, labels, index in tqdm(train_loader):\n",
    "        images[0] = images[0].cuda(non_blocking=True)\n",
    "        images[1] = images[1].cuda(non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            hidden1, hidden2 = model(images[0]), model(images[1])\n",
    "        hidden1, hidden2 = F.normalize(hidden1, p=2, dim=1), F.normalize(hidden2, p=2, dim=1)\n",
    "        hidden_list1.append(hidden1.cpu())\n",
    "        hidden_list2.append(hidden2.cpu())\n",
    "        indices.append(index.cpu())\n",
    "        labels_list.append(labels.cpu())\n",
    "\n",
    "del model\n",
    "\n",
    "hidden1 = torch.cat(hidden_list1, dim=0)\n",
    "hidden2 = torch.cat(hidden_list2, dim=0)\n",
    "indices = torch.cat(indices, dim=0)\n",
    "labels = torch.cat(labels_list, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "small_batch_size = 4096\n",
    "large_batch_size = 128\n",
    "max_count = 100000\n",
    "rng = np.random.default_rng(0)\n",
    "seen = torch.ones_like(lda, dtype=torch.bool)\n",
    "\n",
    "# approx_lda = torch.ones_like(lda)\n",
    "approx_lda = torch.ones((len(lda), 2), dtype=torch.float32)\n",
    "batch_lda = []\n",
    "lda_fn = []\n",
    "batch_fn = []\n",
    "approx_fn = []\n",
    "oracle_fn = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i in tqdm(range(0, len(hidden1), small_batch_size)):\n",
    "        i_lda = lda[indices[i:i+small_batch_size]].cuda()\n",
    "        i_label = labels[i:model_idx+small_batch_size].cuda()\n",
    "        b1 = hidden1[model_idx:i+small_batch_size].cuda()\n",
    "        b2 = hidden2[i:i+small_batch_size].cuda()\n",
    "        sampled_indices = torch.from_numpy(rng.choice(indices, size=min(max_count, len(indices)), replace=False))\n",
    "        # for loop in batches\n",
    "        sim_list = []\n",
    "        curr_batch_lda = []\n",
    "        curr_lda_fn = []\n",
    "        curr_batch_fn = []\n",
    "        curr_approx_fn = []\n",
    "        curr_oracle_fn = []\n",
    "        for j in range(0, len(sampled_indices), large_batch_size):\n",
    "            b_indices = sampled_indices[j:j+large_batch_size]\n",
    "            b1_large = hidden1[b_indices].cuda()\n",
    "            b2_large = hidden2[b_indices].cuda()\n",
    "            labels_large = labels[b_indices].cuda().repeat(2)\n",
    "            assert labels_large.shape[0] == 2 * b1_large.shape[0]\n",
    "            # compute output\n",
    "            sim1 = torch.cat([torch.mm(b1, b1_large.t()), torch.mm(b1, b2_large.t())], dim=1)\n",
    "            sim2 = torch.cat([torch.mm(b2, b1_large.t()), torch.mm(b2, b2_large.t())], dim=1)\n",
    "\n",
    "            sim = torch.cat([sim1, sim2], dim=1)\n",
    "\n",
    "            bl = sim.float().quantile(1-alpha, dim=1, keepdim=True).type_as(i_lda).cuda()\n",
    "            curr_batch_fn.append(\n",
    "                (sim > bl).float().cpu())\n",
    "            curr_lda_fn.append(\n",
    "                (sim > i_lda).float().cpu())\n",
    "            curr_oracle_fn.append(\n",
    "                (labels_large.unsqueeze(0) == i_label.unsqueeze(1)).float().cpu())\n",
    "            curr_batch_lda.append(bl.cpu())\n",
    "            sim_list.append(sim.cpu())\n",
    "\n",
    "        \n",
    "        sim_list = torch.cat(sim_list, dim=1)\n",
    "        curr_batch_lda = torch.cat(curr_batch_lda, dim=1)\n",
    "        curr_batch_fn = torch.cat(curr_batch_fn, dim=1)\n",
    "        curr_lda_fn = torch.cat(curr_lda_fn, dim=1)\n",
    "        curr_oracle_fn = torch.cat(curr_oracle_fn, dim=1)\n",
    "\n",
    "        q_low = sim_list.float().quantile(1-alpha, dim=1, keepdim=True, interpolation='lower').type_as(lda).cpu()\n",
    "        q_high = sim_list.float().quantile(1-alpha, dim=1, keepdim=True, interpolation='higher').type_as(lda).cpu()\n",
    "\n",
    "        curr_approx_fn = (sim_list > q_low).float().cpu()\n",
    "\n",
    "        del sim_list\n",
    "\n",
    "        batch_lda.append(curr_batch_lda)\n",
    "        lda_fn.append(curr_lda_fn)\n",
    "        batch_fn.append(curr_batch_fn)\n",
    "        approx_fn.append(curr_approx_fn)\n",
    "        oracle_fn.append(curr_oracle_fn)\n",
    "        \n",
    "        approx_lda[indices[i:i+small_batch_size],0] = q_low.squeeze(1)\n",
    "        approx_lda[indices[i:i+small_batch_size],1] = q_high.squeeze(1)\n",
    "        seen[indices[i:i+small_batch_size]] = False\n",
    "# assert torch.all(seen), \"Some indices are not seen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hidden1\n",
    "del hidden2\n",
    "del indices\n",
    "del labels\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"results/lambdas\"\n",
    "torch.save(approx_lda, f\"{folder}/approx_lda_{model_idx}.pth\")\n",
    "torch.save(batch_lda, f\"{folder}/batch_lda_{model_idx}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"results/lambdas\"\n",
    "approx_lda = torch.load(f\"{folder}/approx_lda_{model_idx}.pth\")\n",
    "batch_lda = torch.load(f\"{folder}/batch_lda_{model_idx}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_lda = torch.cat(batch_lda, dim=0)\n",
    "lda_fn = torch.cat(lda_fn, dim=0)\n",
    "batch_fn = torch.cat(batch_fn, dim=0)\n",
    "approx_fn = torch.cat(approx_fn, dim=0)\n",
    "oracle_fn = torch.cat(oracle_fn, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = lda.cuda().squeeze()[:-1]\n",
    "approx_lda = approx_lda.cuda().squeeze()[:-1]\n",
    "batch_lda = batch_lda.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    q_low = approx_lda[:,0]\n",
    "    q_high = approx_lda[:,1]\n",
    "    a_lda = torch.where(torch.abs(lda - q_low) < torch.abs(q_high - lda), q_low, q_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = torch.abs(lda.squeeze() - a_lda.squeeze())\n",
    "# mae, rmse, mae_scaled (to 0-100 scale)\n",
    "mae = error.mean().item()\n",
    "rmse = torch.sqrt((error ** 2).mean()).item()\n",
    "mae_scaled = mae * 50\n",
    "print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE scaled: {mae_scaled:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    q_low = approx_lda[:,0].unsqueeze(1)\n",
    "    q_high = approx_lda[:,1].unsqueeze(1)\n",
    "    a_lda = torch.where(torch.abs(batch_lda - q_low) < torch.abs(q_high - batch_lda), q_low, q_high)\n",
    "batch_error = torch.abs(batch_lda - a_lda)\n",
    "# mae, rmse, mae_scaled (to 0-100 scale)\n",
    "mae = batch_error.mean().item()\n",
    "rmse = torch.sqrt((batch_error ** 2).mean()).item()\n",
    "mae_scaled = mae * 50\n",
    "print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE scaled: {mae_scaled:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = error.cpu().numpy()\n",
    "lda = lda.cpu().numpy()\n",
    "a_lda = a_lda.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))  # Optional: Specify figure size\n",
    "plt.plot(error, label='y = x^2', color='blue', linewidth=2)  # Plotting the line\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('X-axis', fontsize=14)\n",
    "plt.ylabel('Y-axis', fontsize=14)\n",
    "plt.title('Line Plot Example', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lda.squeeze() - a_lda.squeeze()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6), dpi=300)\n",
    "# mpl.rcParams['pdf.fonttype'] = 42\n",
    "# mpl.rcParams['ps.fonttype'] = 42\n",
    "# mpl.rcParams['font.family'] = 'Arial'\n",
    "            \n",
    "# Plot the kernel density plot for lda\n",
    "v_plot = (lda.squeeze() - a_lda.squeeze())\n",
    "ax = sns.kdeplot(v_plot, color='blue', legend=False, linewidth=12)\n",
    "ax.yaxis.set_visible(False)\n",
    "plt.tick_params(axis='x', labelsize=40)\n",
    "plt.xlabel(\"\\u03BB\", fontsize=45)\n",
    "plt.xlim(-0.5, 0.5)\n",
    "# plt.xticks(np.arange(0.1, 0.7, 0.1))\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"plots/lda_199.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 6), dpi=300)\n",
    "# mpl.rcParams['pdf.fonttype'] = 42\n",
    "# mpl.rcParams['ps.fonttype'] = 42\n",
    "# mpl.rcParams['font.family'] = 'Arial'\n",
    "            \n",
    "# Plot the kernel density plot for lda\n",
    "v_plot = error\n",
    "ax = sns.kdeplot(v_plot, color='blue', legend=False, linewidth=12)\n",
    "ax.yaxis.set_visible(False)\n",
    "plt.tick_params(axis='x', labelsize=40)\n",
    "plt.xlabel(\"\\u03BB\", fontsize=45)\n",
    "plt.xlim(0, 0.5)\n",
    "# plt.xticks(np.arange(0.1, 0.7, 0.1))\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"plots/lda_199.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6), dpi=300)\n",
    "# mpl.rcParams['pdf.fonttype'] = 42\n",
    "# mpl.rcParams['ps.fonttype'] = 42\n",
    "# mpl.rcParams['font.family'] = 'Arial'\n",
    "            \n",
    "# Plot the kernel density plot for lda\n",
    "v_plot = lda.squeeze()\n",
    "v2_plot = a_lda.squeeze()\n",
    "ax = sns.kdeplot(v_plot, color='blue', legend=False, linewidth=12)\n",
    "sns.kdeplot(v2_plot, color='red', legend=False, linewidth=12, ax=ax)\n",
    "ax.yaxis.set_visible(False)\n",
    "plt.tick_params(axis='x', labelsize=40)\n",
    "plt.xlabel(\"\\u03BB\", fontsize=45)\n",
    "plt.xlim(0.1, 0.6)\n",
    "# plt.xticks(np.arange(0.1, 0.7, 0.1))\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"plots/lda_199.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6), dpi=300)\n",
    "# mpl.rcParams['pdf.fonttype'] = 42\n",
    "# mpl.rcParams['ps.fonttype'] = 42\n",
    "# mpl.rcParams['font.family'] = 'Arial'\n",
    "            \n",
    "# Plot the kernel density plot for lda\n",
    "v_plot = lda.squeeze()\n",
    "v2_plot = a_lda.squeeze()\n",
    "v3_plot = batch_lda.cpu().numpy()\n",
    "randomlist = random.sample(range(0, v3_plot.shape[1]), 50)\n",
    "ax = sns.kdeplot(v_plot, color='blue', legend=True, linewidth=12, label='Real')\n",
    "sns.kdeplot(v2_plot, color='red', legend=True, linewidth=12, ax=ax, label=r'$\\lambda$')\n",
    "sns.kdeplot(v3_plot[:,randomlist[0]],legend=True, linewidth=12, ax=ax, alpha=0.5, label=\"FNC\")\n",
    "lines = ax.lines\n",
    "for k in randomlist[1:]:\n",
    "    sns.kdeplot(v3_plot[:,k],legend=True, linewidth=12, ax=ax, alpha=0.5)\n",
    "\n",
    "ax.yaxis.set_visible(False)\n",
    "plt.tick_params(axis='x', labelsize=40)\n",
    "plt.xlabel(\"\\u03BB\", fontsize=45)\n",
    "plt.xlim(0.1, 0.6)\n",
    "# plt.xticks(np.arange(0.1, 0.7, 0.1))\n",
    "plt.legend(handles=ax.lines, loc='upper right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"plots/lda_199.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
